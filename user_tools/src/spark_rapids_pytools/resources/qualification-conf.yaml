toolOutput:
  completeOutput: true
  subFolder: rapids_4_spark_qualification_output
  csv:
    summaryReport:
      fileName: rapids_4_spark_qualification_output.csv
      columns:
        - App Name
        - App ID
        - Recommendation
        - Estimated GPU Speedup
        - Estimated GPU Duration
        - App Duration
        - Estimated Job Frequency (monthly)
      mapColumns:
        Recommendation: 'Speedup Based Recommendation'
      recommendations:
        speedUp:
          columnName: 'Speedup Based Recommendation'
          selectedRecommendations:
            - 'Strongly Recommended'
            - 'Recommended'
        savings:
          columnName: 'Savings Based Recommendation'
          selectedRecommendations:
            - 'Strongly Recommended'
            - 'Recommended'
      groupColumns:
         App Duration: 'App Name'
         Estimated GPU Duration: 'App Name'
      dropDuplicates:
         - App Name
  stdout:
    summaryReport:
      compactWidth: true
      timeUnits: 's'
      columnWidth: 14
sparkRapids:
  mvnUrl: 'https://repo1.maven.org/maven2/com/nvidia/rapids-4-spark-tools_2.12'
  repoUrl: '{}/{}/rapids-4-spark-tools_2.12-{}.jar'
  mainClass: 'com.nvidia.spark.rapids.tool.qualification.QualificationMain'
  outputDocURL: 'https://nvidia.github.io/spark-rapids/docs/spark-qualification-tool.html#understanding-the-qualification-tool-output'
  gpu:
    device: 't4'
    workersPerNode: 2
    cudaVersion: '11.5'
  cli:
    defaults:
      filters:
        defaultFilter: 'SAVINGS'
      gpuClusterRecommendation:
        defaultRecommendation: 'MATCH'
    toolOptions:
      - all
      - any
      - a
      - application-name
      - f
      - filter-criteria
      - h
      - html-report
      - no-html-report
      - m
      - match-event-logs
      - max-sql-desc-length
      - ml-functions
      - n
      - num-output-rows
      - num-threads
      - order
      - p
      - per-sql
      - r
      - report-read-schema
      - s
      - spark-property
      - start-app-time
      - t
      - timeout
      - u
      - user-name
local:
  output:
    cleanUp: true
    fileName: qualification_summary.csv
    costColumns:
      - 'Savings Based Recommendation'
      - 'Estimated App Cost'
      - 'Estimated GPU Cost'
      - 'Estimated GPU Savings(%)'
      - 'Estimated Job Frequency (monthly)'
      - 'Annual Cost Savings'
    savingColumn: 'Estimated GPU Savings(%)'
    speedupRecommendColumn: 'Speedup Based Recommendation'
    savingRecommendColumn: 'Savings Based Recommendation'
    summaryColumns: #columns to be displayed on the stdout as part of the final report
      savingsReportEnabledTrue: #columns with savings estimates enabled
        - 'App ID'
        - 'App Name'
        - 'Speedup Based Recommendation'
        - 'Savings Based Recommendation'
        - 'App Duration'
        - 'Estimated GPU Duration'
        - 'Estimated GPU Speedup'
        - 'Estimated GPU Savings(%)'
      savingsReportEnabledFalse: #columns with savings estimates disabled
        - 'App ID'
        - 'App Name'
        - 'Speedup Based Recommendation'
        - 'App Duration'
        - 'Estimated GPU Duration'
        - 'Estimated GPU Speedup'
    processDFProps:
      minimumWorkerCount: 2
      gpuScaleFactor: 0.80
      savingRecommendationsRanges:
        nonRecommended:
          title: 'Not Recommended'
          lowerBound: -1000000.0
          upperBound: 1.0
        recommended:
          title: 'Recommended'
          lowerBound: 1.0
          upperBound: 30.0
        stronglyRecommended:
          title: 'Strongly Recommended'
          lowerBound: 30.0
          upperBound: 1000000.0
      clusterShapeCols:
        columnName: 'Recommended Cluster Shape'
        noteMsg: 'The GPU estimations are done with a recommended GPU cluster shape of {} worker nodes'
        colsPerShapeType:
          CLUSTER:
            excludeColumns:
              - 'Speedup Based Recommendation'
              - 'Estimated GPU Speedup'
          JOB:
            excludeColumns:
              - 'Speedup Based Recommendation'
              - 'Estimated GPU Speedup'
            appendColumns:
              - columnName: 'Recommended Cluster Shape'
                index: 4
    treeDirectory:
      enabled: true
      depthLevel: 4
      indentation: '    '
      excludedPatterns:
        directories:
          - '^(css)$'
          - '^(js)$'
          - '^(assets)$'
          - '.+\$$'
          - '^.+(_\$folder\$)$'
        files:
          - '^(\.+).*'
          - '^(\$+).*'
          - '^.+(_\$folder\$)$'
  clusterConfigs:
    constants:
      # Maximum amount of pinned memory to use per executor in megabytes
      maxPinnedMemoryMB: 4096
      # Default pageable pool size per executor in megabytes
      defaultPageablePoolMB: 1024
      # Maximum number of concurrent tasks to run on the GPU
      maxGpuConcurrent: 4
      # Amount of GPU memory to use per concurrent task in megabytes
      # Using a bit less than 8GB here since Dataproc clusters advertise
      # T4s as only having around 14.75 GB and we want to run with
      # 2 concurrent by default on T4s.
      gpuMemPerTaskMB: 7500
      # Ideal amount of JVM heap memory to request per CPU core in megabytes
      heapPerCoreMB: 2048
      # Fraction of the executor JVM heap size that should be additionally reserved
      # for JVM off-heap overhead (thread stacks, native libraries, etc.)
      heapOverheadFraction: 0.1
      # Amount of CPU memory to reserve for system overhead (kernel, buffers, etc.) in megabytes
      systemReserveMB: 2048
      # By default set the spark.sql.files.maxPartitionBytes to 512m
      maxSqlFilesPartitionsMB: 512
platform:
  shortName: 'qual'
  outputDir: qual-tool-output
  cleanUp: true

