# Copyright (c) 2023, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Wrapper class to run tools associated with RAPIDS Accelerator for Apache Spark plugin."""

import tempfile

import fire

from pyrapids.cloud_api.sp_types import CloudPlatform, DeployMode
from pyrapids.common.utilities import ToolLogging
from pyrapids.rapids.bootstrap import Bootstrap
from pyrapids.rapids.qualification import Qualification, QualificationAsLocal


class CliEmrLocalMode:  # pylint: disable=too-few-public-methods
    """
    A wrapper that runs the RAPIDS Accelerator tools locally on the dev machine.
    """

    @staticmethod
    def qualification(cpu_cluster: str,
                      profile: str = 'default',
                      local_folder: str = '.',
                      remote_folder: str = None,
                      eventlogs: str = None,
                      gpu_cluster: str = None,
                      tools_jar: str = None,
                      filter_apps: str = 'savings',
                      gpu_device: str = 'T4',
                      gpu_per_machine: int = 2,
                      cuda: str = '11.5',
                      jvm_heap_size: int = '24',
                      verbose: bool = False,
                      **rapids_options) -> None:
        """
        The Qualification tool analyzes Spark events generated from CPU based Spark applications to
        help quantify the expected acceleration and costs savings of migrating a Spark application
        or query to GPU. The wrapper downloads dependencies and executes the analysis on the local
        dev machine.
        :param cpu_cluster: The EMR-cluster on which the Spark applications were executed. The argument
                can be an EMR-cluster or a valid path to the cluster's properties file (json format)
                generated by the AWS CLI.
        :param profile: A named AWS profile to get the settings/credentials of the AWS account.
        :param local_folder: Local work-directory path to store the output and to be used as root
                directory for temporary folders/files. The final output will go into a subdirectory called
                ${local_folder}/qual-${EXEC_ID} where exec_id is an auto-generated unique identifier of the
                execution.
        :param remote_folder: An S3 folder where the output is uploaded at the end of execution.
                If no value is provided, the output will be only available on local disk.
        :param eventlogs: Event log filenames as S3 storage directories containing event logs (comma separated).
                If not specified, the wrapper will pull the default logs directory from the cluster
                properties, which is equivalent to s3://${BUCKET_NAME}/logs/${cluster_id}
        :param gpu_cluster: The EMR-cluster on which the Spark applications is planned to be migrated.
                The argument can be an EMR-cluster or a valid path to the cluster's properties file
                (json format) generated by the AWS CLI. If missing, the wrapper maps the EC2 machine
                instances of the original cluster into EC2 instances that support GPU acceleration.
        :param tools_jar: Path to a bundled jar including Rapids tool. The path is a local filesystem,
                or remote S3 url. If missing, the wrapper downloads the latest rapids-4-spark-tools_*.jar
                from maven repo.
        :param filter_apps: The filtering criteria of the applications listed in the final STDOUT table.
                Note that this filter does not affect the CSV report.
                "NONE" means no filter applied. "recommended" lists all the apps that are either
                'Recommended', or 'Strongly Recommended'. "savings" lists all the apps that have positive
                estimated GPU savings.
        :param gpu_device: The type of the GPU to add to the cluster. Options are [T4, V100, K80, A100, P100].
        :param gpu_per_machine: The number of GPU accelerators to be added to each VM image.
        :param cuda: cuda version to be used with the GPU accelerator.
        :param verbose: True or False to enable verbosity to the wrapper script.
        :param jvm_heap_size: The maximum heap size of the JVM in gigabytes.
        :param rapids_options: A list of valid Qualification tool options.
                Note that the wrapper ignores the “output-directory“ flag, and it does not support
                multiple “spark-property“ arguments.
                For more details on Qualification tool options, please visit
                https://nvidia.github.io/spark-rapids/docs/spark-qualification-tool.html#qualification-tool-options
        """
        if verbose:
            # when debug is set to true set it in the environment.
            ToolLogging.enable_debug_mode()
        wrapper_qual_options = {
            'platformOpts': {
                'profile': profile,
                'deployMode': DeployMode.LOCAL,
            },
            'migrationClustersProps': {
                'cpuCluster': cpu_cluster,
                'gpuCluster': gpu_cluster
            },
            'jobSubmissionProps': {
                'remoteFolder': remote_folder,
                'platformArgs': {
                    'jvmMaxHeapSize': jvm_heap_size
                }
            },
            'eventlogs': eventlogs,
            'filterApps': filter_apps,
            'toolsJar': tools_jar,
            'gpuDevice': gpu_device,
            'gpuPerMachine': gpu_per_machine,
            'cuda': cuda
        }
        QualificationAsLocal(platform_type=CloudPlatform.EMR,
                             cluster=None,
                             output_folder=local_folder,
                             wrapper_options=wrapper_qual_options,
                             rapids_options=rapids_options).launch()

    @staticmethod
    def bootstrap(cluster: str = None,
                  profile: str = 'default',
                  output_folder: str = '.',
                  dry_run: bool = True,
                  verbose: bool = False) -> None:
        """
        Bootstrap tool analyzes the CPU and GPU configuration of the EMR cluster
        and updates the Spark default configuration on the cluster's master nodes.

        :param cluster: Name of the EMR cluster running an accelerated computing instance class g4dn.*
        :param profile: A named AWS profile to get the settings/credentials of the AWS account.
        :param output_folder: Base output directory. The final recommendations will be logged in the
               subdirectory 'wrapper-output/rapids_user_tools_bootstrap'.
               Note that this argument only accepts local filesystem.
        :param dry_run: True or False to update the Spark config settings on EMR master node.
        :param verbose: True or False to enable verbosity to the wrapper script.
        """
        if verbose:
            # when debug is set to true set it in the environment.
            ToolLogging.enable_debug_mode()
        wrapper_boot_options = {
            'platformOpts': {
                'profile': profile,
            },
            'dry_run': dry_run
        }
        bootstrap_tool = Bootstrap(platform_type=CloudPlatform.EMR,
                                   cluster=cluster,
                                   output_folder=output_folder,
                                   wrapper_options=wrapper_boot_options)
        bootstrap_tool.launch()


class CliEmrServerlessMode:  # pylint: disable=too-few-public-methods
    """
    A wrapper that runs the logic as an EMR-serverless application.
    """

    @staticmethod
    def qualification(eventlogs: str,
                      cpu_cluster: str,
                      remote_folder: str,
                      job_arn: str,
                      profile: str = 'default',
                      app_id: str = None,
                      gpu_cluster: str = None,
                      local_folder: str = None,
                      tools_jar: str = None,
                      filter_apps: str = 'savings',
                      gpu_device: str = 'T4',
                      gpu_per_machine: int = 2,
                      cuda: str = '11.5',
                      verbose: bool = False,
                      **rapids_options) -> None:
        """
        The Qualification tool analyzes Spark events generated from CPU based Spark applications to
        help quantify the expected acceleration and costs savings of migrating a Spark application
        or query to GPU. The wrapper submits Spark EMR-Serverless job to run the RAPIDS accelerator.

        :param eventlogs: Event log filenames or S3 storage directories
            containing event logs (comma separated).
        :param cpu_cluster: The EMR-cluster on which the Spark applications were executed. The argument
               can be an EMR-cluster or a valid path to the cluster's properties file (json format)
               generated by the AWS CLI.
        :param remote_folder: The S3 folder where the output is archived.
        :param job_arn: The execution role ARN for the job run.
        :param app_id: The ID of the EMR-serverless application on which to run the job.
                If missing, the wrapper creates an EMR-serverless application that gets deleted at
                the end of the execution. Note that creating an EMR-serverless application takes a few
                minutes.
        :param gpu_cluster: The EMR-cluster on which the Spark applications is planned to be migrated.
                The argument can be an EMR-cluster or a valid path to the cluster's properties file
                (json format) generated by the AWS CLI. If missing, the wrapper maps the EC2 machine
                instances of the original cluster into EC2 instances that support GPU acceleration.
        :param local_folder: Local work-directory path to store the output and to be used as root
                directory for temporary folders/files. This argument helps to specify if the final output
                should be locally downloaded to the local development machine.
                If missing, the wrapper will create a temporary directory and gets deleted at the end of execution.
        :param profile: A named AWS that you can specify to get the settings/credentials of the AWS account.
        :param tools_jar: Path to a bundled jar including Rapids tool. The path is a local filesystem,
                or remote S3 url. If missing, the wrapper downloads the latest rapids-4-spark-tools_*.jar
                from maven repo.
        :param filter_apps: [NONE | recommended | savings] filtering criteria of the applications
            listed in the final STDOUT table. Note that this filter does not affect the CSV report.
            “NONE“ means no filter applied. “recommended“ lists all the apps that are either
            'Recommended', or 'Strongly Recommended'. “savings“ lists all the apps that have positive
            estimated GPU savings.
        :param gpu_device: The type of the GPU to add to the cluster. Options are [T4, V100, K80, A100, P100].
        :param gpu_per_machine: The number of GPU accelerators to be added to each VM image.
        :param cuda: cuda version to be used with the GPU accelerator.
        :param verbose: True or False to enable verbosity to the wrapper script.
        :param rapids_options: A list of valid Qualification tool options.
            Note that the wrapper ignores the “output-directory“ flag, and it does not support
            multiple “spark-property“ arguments.
            For more details on Qualification tool options, please visit
            https://nvidia.github.io/spark-rapids/docs/spark-qualification-tool.html#qualification-tool-options
        """
        if verbose:
            # when debug is set to true set it in the environment.
            ToolLogging.enable_debug_mode()
        wrapper_qual_options = {
            'platformOpts': {
                'profile': profile,
                'deployMode': DeployMode.SERVERLESS,
            },
            'migrationClustersProps': {
                'cpuCluster': cpu_cluster,
                'gpuCluster': gpu_cluster
            },
            'jobSubmissionProps': {
                'remoteFolder': remote_folder,
                'platformArgs': {
                    'application-id': app_id,
                    'execution-role-arn': job_arn,
                }
            },
            'eventlogs': eventlogs,
            'filterApps': filter_apps,
            'toolsJar': tools_jar,
            'gpuDevice': gpu_device,
            'gpuPerMachine': gpu_per_machine,
            'cuda': cuda
        }
        with tempfile.TemporaryDirectory() as exec_tmp_folder:
            if local_folder is None:
                local_folder = exec_tmp_folder
                local_folder = '.'
            Qualification(platform_type=CloudPlatform.EMR,
                          cluster=None,
                          output_folder=local_folder,
                          wrapper_options=wrapper_qual_options,
                          rapids_options=rapids_options).launch()


class EMRWrapper:  # pylint: disable=too-few-public-methods
    """
    A wrapper script to run RAPIDS Accelerator tools (Qualification, Profiling, and Bootstrap) on Amazon EMR.
    :param mode: The deployment mode of the tool command from RAPIDS Accelerator for Apache Spark. Accepted options
                are <local|serverless>. local means that the tool runs locally on the development machine.
                "serverless" means that the wrapper will trigger an Amazon EMR cluster to submit a new job.
    """

    def __init__(self, mode: str = DeployMode.pretty_print(DeployMode.LOCAL)):
        self.mode = mode
        if DeployMode.fromstring(self.mode) == DeployMode.SERVERLESS:
            self.qualification = CliEmrServerlessMode.qualification
            self.bootstrap = CliEmrLocalMode.bootstrap
        else:
            self.qualification = CliEmrLocalMode.qualification
            self.bootstrap = CliEmrLocalMode.bootstrap


def main():
    fire.Fire({
        'emr': EMRWrapper,
    })


if __name__ == '__main__':
    main()
