# Copyright (c) 2024-2025, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# tox (https://tox.readthedocs.io/) is a tool for running tests
# in multiple virtualenvs. This configuration file will run the
# test suite on all supported python versions. To use it, "pip install tox"
# and then run "tox" from this directory.

[tox]
envlist =
    prepare
    python{3.10,3.11,3.12}
    coverage
    pylint
    flake8
    behave
isolated_build = True

[gh-actions]
python =
    3.10: prepare, python3.10, pylint, flake8, behave
    3.11: prepare, python3.11, pylint, flake8, behave
    3.12: prepare, python3.12, pylint, flake8, behave

[testenv]
deps =
    pytest
    pytest-cov
    cli_test_helpers
    behave
extras = test
setenv =
    COVERAGE_FILE = {env:COVERAGE_FILE:{toxworkdir}/.coverage.{envname}}
passenv =
    # propagate RAPIDS_USER_TOOLS_* environment variables configured in GitHub Actions
    RAPIDS_USER_TOOLS_*
commands =
    pytest -vv \
    --cov "{envsitepackagesdir}/spark_rapids_pytools" \
    --cov-config "{toxinidir}/tox.ini" \
    {posargs:tests}

[testenv:pylint]
deps =
    pylint==3.3.7
    pytest
commands = pylint -d fixme --load-plugins pylint_pydantic --rcfile=../.pylintrc \
           tests \
           src
depends =
    prepare

[testenv:coverage]
deps = coverage
setenv =
    COVERAGE_FILE = {toxworkdir}/.coverage
commands =
    coverage combine
    coverage report
depends =
    prepare
    python3.10
    python3.11
    python3.12

[coverage:paths]
source = src/spark_rapids_pytools
         src/spark_rapids_tools
         */.tox/*/lib/python*/site-packages/spark_rapids_pytools
         */.tox/pypy*/site-packages/spark_rapids_pytools
         */.tox/*/lib/python*/site-packages/spark_rapids_tools
         */.tox/pypy*/site-packages/spark_rapids_tools

[testenv:flake8]
deps = flake8
commands = flake8 \
           tests \
           src
depends =
    prepare

[flake8]
# ignore line-too-long flag
extend-ignore =
    E501
exclude = .tox,build,dist
# exclude "imported but unused" for compat.py
per-file-ignores = src/spark_rapids_tools/utils/compat.py:F401

[testenv:behave]
deps = behave
passenv	=
    JAVA_HOME
    RAPIDS_USER_TOOLS_*
extras = dev-env
depends =
    prepare
commands = behave {posargs}

#This step builds the jar and copies the report files + jar from core
#to spark_rapids_pytools/resources/generated_files.
#The jar + report files are then used by the python project.
[testenv:prepare]
description = Generate Tools JAR and copy reports into generated_files prior to isolated builds
passenv = JAVA_HOME
setenv =
    TOOLS_SPARK_BUILDVER = {env:TOOLS_SPARK_BUILDVER:350}
    TOOLS_HADOOP_VERSION = {env:TOOLS_HADOOP_VERSION:3.3.6}
    TOOLS_MAVEN_ARGS = {env:TOOLS_MAVEN_ARGS:-Dbuildver={env:TOOLS_SPARK_BUILDVER} -Dhadoop.version={env:TOOLS_HADOOP_VERSION}}
allowlist_externals = bash
skip_install = true
commands =
    bash -lc "cd {toxinidir} && SKIP_WHEEL_PACKAGE_BUILD=1 ./build.sh non-fat"

[testenv:python3.10]
depends = prepare

[testenv:python3.11]
depends = prepare

[testenv:python3.12]
depends = prepare

[behave]
paths = tests/spark_rapids_tools_e2e/features
stderr_capture = false
