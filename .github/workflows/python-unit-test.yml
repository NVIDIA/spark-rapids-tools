# Copyright (c) 2023-2025, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# A workflow to run Python unit test for user tools
name: Python unit test

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  prepare-deps:
    runs-on: ubuntu-latest
    env:
      RAPIDS_USER_TOOLS_CACHE_FOLDER: ${{ github.workspace }}/.cache/spark_rapids_user_tools_cache
    steps:
      - name: Checkout code
        uses: NVIDIA/spark-rapids-common/checkout@main

      - name: Prefetch heavy on-prem dependency artifacts
        shell: bash
        run: |
          chmod +x scripts/prefetch_deps.sh
          scripts/prefetch_deps.sh "$RAPIDS_USER_TOOLS_CACHE_FOLDER" "onprem,dataproc,emr,databricks_aws,databricks_azure" "user_tools/src/spark_rapids_pytools/resources"

      - name: Upload RAPIDS cache artifact
        uses: actions/upload-artifact@v4
        with:
          name: rapids-cache
          path: ${{ env.RAPIDS_USER_TOOLS_CACHE_FOLDER }}

  prepare-tools:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: NVIDIA/spark-rapids-common/checkout@main

      - name: Install Maven
        run: sudo apt-get update && sudo apt-get install -y maven

      - name: Build tools JAR and copy reports (prepare)
        run: |
          cd user_tools
          TOOLS_MAVEN_ARGS="-Dbuildver=356 -Dhadoop.version=3.3.6" \
          SKIP_WHEEL_PACKAGE_BUILD=1 \
          ./build.sh non-fat

      - name: Upload generated tools resources
        uses: actions/upload-artifact@v4
        with:
          name: tools-generated
          path: user_tools/src/spark_rapids_pytools/resources/generated_files

  build:
    needs: [prepare-deps, prepare-tools]
    runs-on: ubuntu-latest
    env:
      # Ensure all runtime downloads (Spark archives, jars, temp build artifacts) land in a
      # repo-local cache folder so they can be restored across matrix jobs via actions/cache
      RAPIDS_USER_TOOLS_CACHE_FOLDER: ${{ github.workspace }}/.cache/spark_rapids_user_tools_cache
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: Checkout code
        uses: NVIDIA/spark-rapids-common/checkout@main

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Restore RAPIDS cache artifact
        uses: actions/download-artifact@v4
        with:
          name: rapids-cache
          path: ${{ env.RAPIDS_USER_TOOLS_CACHE_FOLDER }}

      - name: Restore generated tools resources
        uses: actions/download-artifact@v4
        with:
          name: tools-generated
          path: user_tools/src/spark_rapids_pytools/resources/generated_files

      - name: Install tox
        run: |
          python -m pip install --upgrade pip
          python -m pip install tox
          python -m pip install --pre tox-gh-actions

      - name: Run tox test
        # Set TOX_RUN_PREPARE empty so tox does not depend on the "prepare" env.
        # tox.ini contains: depends = {env:TOX_RUN_PREPARE:prepare}
        # Leaving it empty removes that dependency because prepare artifacts were built earlier
        # in the prepare-tools and prepare-deps jobs and downloaded above.
        run: cd user_tools && TOX_RUN_PREPARE= tox
